<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
  <script type="text/javascript">

    var BUFF_SIZE = 16384;
    var audioContext;
    var sessionID, sequence;

    function sendBuffer(sessionID, seq, samples, sampleRate, retryCount) {
      if (retryCount <= 0) {
        console.info('reach max retry, stop sending samples with sessionID=' + sessionID + ', sequence=' + seq);
        return;
      }
      httpRequest = new XMLHttpRequest();
      httpRequest.onreadystatechange = function () {
        if (httpRequest.readyState === 4 && httpRequest.status != 200) {
          console.log('failed to send samples with sessionID=' + sessionID + ', sequence=' + seq);
          sendBuffer(sessionID, seq, samples, sampleRate, retryCount - 1);
        }
      }

      console.log('sending samples with sessionID=' + sessionID + ', sequence=' + seq + ', remaining retries=' + retryCount);
      httpRequest.open('PUT', '/recognize/' + sessionID + '?sequence=' + seq, true);
      var response = httpRequest.send(samples);
    }

    function float32ToInt16(samples) {
      var index = samples.length;
      var int16Buffer = new Int16Array(index);
      var clippedValue;
      while (index--) {
        clippedValue = Math.max(-1, Math.min(1, samples[index]))
        int16Buffer[index] = clippedValue > 0 ? clippedValue * 0x7FFF : clippedValue * 0x8000
      }
      return int16Buffer;
    }

    function record() {
      if (audioContext) {
        console.info('already recording...');
        return;
      }
      audioContext = new (window.AudioContext || window.webKitAudioContext)();
      navigator.webkitGetUserMedia({ audio: true }, function (stream) {
        sessionID = (Math.random() * new Date().getMilliseconds()).toString(36);
        sequence = 0;
        var microphoneSource = audioContext.createMediaStreamSource(stream);
        var streamingProcessor = audioContext.createScriptProcessor(BUFF_SIZE, 1, 1);
        streamingProcessor.onaudioprocess = function (audioProcessingEvent) {
          var samples = audioProcessingEvent.inputBuffer.getChannelData(0);
          console.info('processing samples from microphone, length=' + samples.length);
          var int16Buffer = float32ToInt16(samples)
          sendBuffer(sessionID, sequence++, int16Buffer, audioProcessingEvent.inputBuffer.sampleRate, 5);
        };
        microphoneSource.connect(streamingProcessor);
        streamingProcessor.connect(audioContext.destination);
      },
        function (error) {
          console.error('unable to access audio device:' + error);
        })
    }

    function stop() {
      if (sessionID) {
        var url = '/recognize/' + sessionID + '?sequence=' + sequence + '&finished=true&sampleRate=' + audioContext.sampleRate
        sessionID = undefined;
        sequence = undefined;
        httpRequest = new XMLHttpRequest();
        httpRequest.open('PUT', url, true);
        httpRequest.send();
      }
      if (audioContext) {
        audioContext.close();
        audioContext = undefined;
      }
    }

  </script>
</head>

<body>
  <h1>Google Speech API Demo</h1>
  <br/>
  <div>
    <span>Synchronize Recognition</span>
  </div>
  <div>
    <button onclick="stop()">Stop</button>
    <button onclick="record()">Start</button>
  </div>
  <div>
    <textarea rows="10" cols="120"></textarea>
  </div>

</body>

</html>